---
title: Spaceship Titanic Investigation
author: 
  - name: Adam Gilbert
    email: a.gilbert1@snhu.edu
    affiliations: 
      - name: Southern New Hampshire University
format: html
date: 9/15/2023
date-modified: today
date-format: long
theme: flatly
toc: true
code-fold: true
---

```{r setup}
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
library(patchwork)
library(kableExtra)
library(ggridges)
library(marginaleffects)

data <- read_csv("https://raw.githubusercontent.com/agmath/agmath.github.io/master/data/classification/spaceship_titanic.csv")

names(data) <- janitor::make_clean_names(names(data))

data <- data %>%
  mutate(
    transported = factor(transported)
  )

data_splits <- initial_split(data, prop = 0.8, strata = transported)

train <- training(data_splits)
test <- testing(data_splits)
```

## Statement of Purpose

Like its namesake vessel, the *Spaceship Titanic* encountered tragedy when several of its passengers were warped to an alternate dimension during flight! This analysis is a post-mortem on the flight and passenger list so that we may better understand who is at risk for interdimensional transport during spaceflight and can take future precautionary measures.

## Executive Summary

:::{.callout-note}
Intentionally left blank, for now. This is the last section to be written.
:::

## Introduction

The year is 2063. We’ve come a long way from the early 2020’s, where billionaire tech entrepreneurs launched tiny rockets, holding a handful of celebrities or wealthy elites, into near-Earth orbit for an exorbitant pricetag. The future is now…well, was last week… Things are much more uncertain now. We were so excited with the launch of the Spaceship Titanic. It was supposed to be the beginning of a new era – affordable, long-range space travel for everyone. In hindsight, perhaps naming the thing the Titanic was a poor decision – too tempting for fate and karma.

In any case, space travel is an important venture for humanity at this point in our history as a species. Demand is high, even with last week’s disaster. We have a vested interest in safe and reliable travel through the cosmos and need to better understand what happened to the travelers who’ve disappeared and why it happened to them and not other passengers. Demand for space travel was expected to reach 86 million travelers next year – we can’t continue if we only expect 43 million passengers to arrive at their intended destination.

## Exploratory Data Analysis

The original data set on the passengers contained `r data %>% nrow()` passengers and `r data %>% ncol()` features (variables). We can see the first-few passengers'-worth of data printed out below.

```{r}
data %>%
  head() %>%
  kable()
```

That data was split into a collection of `r train %>% nrow()` training observations and `r test %>% nrow()` test observations for validating our final model's performance. Care was taken to ensure that the passengers who were *transported* to an alternate dimension are proportionally represented across the *training* and *test* sets.

### Univariate Analyses

Since our goal is to understand who was transported to an alternate dimension during flight and perhaps gain some insight as to why they were transported, we’ll start by understanding the transported variable and the distributions of the other variables available to us.

```{r}
train %>%
  ggplot() + 
  geom_bar(aes(x = transported)) + 
  labs(title = "Distribution of Transported Passengers",
       x = "Interdimensional Transport Status",
       y = "Count")
```

```{r}
pct_transported <- train %>%
  count(transported) %>%
  ungroup() %>%
  mutate(pct = 100*n/sum(n)) %>%
  filter(transported == "yes") %>%
  pull(pct)
```

The percentage of passengers transported in the training set is about `r round(pct_transported, 2)`%. Let’s look at the distributions of the other categorical variables in the data set.

```{r}
p1 <- train %>%
  ggplot() + 
  geom_bar(aes(x = home_planet)) + 
  labs(
    title = "Boarding Planet",
    x = "",
    y = "Count"
  ) + 
  coord_flip()

p2 <- train %>%
  ggplot() + 
  geom_bar(aes(x = cryo_sleep)) +
  labs(
    title = "CryoSleep Selection",
    y = "Count",
    x = ""
  )

p3 <- train %>%
  ggplot() + 
  geom_bar(aes(x = destination)) + 
  labs(
    title = "Destination Planet",
    x = "",
    y = "Count"
  ) + 
  coord_flip()

p4 <- train %>%
  ggplot() + 
  geom_bar(aes(x = vip)) + 
  labs(
    title = "VIP Status",
    x = "",
    y = "Count"
  )

(p1 + p2) / (p3 + p4)
```

From the top-left plot, we see that the majority of passengers board on Earth, while fewer passengers board on Europa and Mars. Some passengers have no boarding planet information (`NA`) – perhaps these passengers are crew members. In the top-right plot, we see that nearly 2/3 of passengers choose the Cryo Sleep option, while around 1/3 do not. Again, some passengers have missing data here. The distribution of destination planet is shown in the lower-right, and tells us that the most popular destination (by a large margin) is TRAPPIST-1e. The only other two destination planets are PSO J318.5-22 and 55 Cancri e. As in the previous plots, some passengers do not have an identified destination. Finally, the proportion of passengers with VIP status is about 2.23.

In each of the plots, we identified several passengers with missing values. There are 0 passengers missing information for all four of these variables. This means that our earlier conjecture about those passengers being crew is unlikely.

Let’s continue on to view the distributions of the numerical predictors available to us. We’ll start with the distribution of passenger ages.

```{r}
#| message: false
#| warning: false

train %>%
  ggplot() + 
  geom_histogram(aes(x = age), color = "black",
                 fill = "purple") + 
  labs(
    title = "Passenger Ages",
    x = "Age (Years)",
    y = ""
  )
```

The plot above shows a [near] 0-inflated distribution. That is, there is an inflated number of observations near 0, given the shape of the rest of the distribution. Ages are right-skewed, with a median passenger age of 27 years old. Next we’ll look at the distribution of room service charges.

```{r}
#| message: false
#| warning: false

p1 <- train %>%
  ggplot() + 
  geom_density(aes(x = room_service),
               fill = "purple",
               color = "black") + 
  geom_boxplot(aes(x = room_service, y = -0.005),
               fill = "purple",
               width = 0.002) + 
  labs(
    title = "Room Service Money Spent",
    x = "Expenditure",
    y = ""
    )

p2 <- train %>%
  ggplot() + 
  geom_density(aes(x = room_service),
               fill = "purple",
               color = "black") + 
  geom_boxplot(aes(x = room_service, y = -0.05),
               fill = "purple",
               width = 0.02) + 
  labs(
    title = "Room Service Money Spent",
    x = "Expenditure",
    y = ""
    ) + 
  scale_x_log10()

p1 + p2
```

Both of the plots above show the distribution of room service expenditures. From the plot on the left, we can see that the distribution is very strongly right-skewed. The majority of passengers spent very little on room service, but there were some passengers who ran up extremely large tabs! The plot on the right shows the same variable but on a logarithmic scale. This particular transformation ignores passengers who did not spend any money on room service. From this plot, we actually see that the median room service expenditure among passengers who utilized room service is quite high – it is about `r median(train$room_service)`. We’ll continue our exploration of the available numerical features below, by working with the expenditures at the food court, shopping mall, spa, and VR deck. All of these are right skewed so we’ll just show the distributions on a logarithmic scale.

```{r}
#| warning: false
#| messae: false

p_food <- train %>%
  ggplot() + 
  geom_density(aes(x = food_court), fill = "purple") + 
  geom_boxplot(aes(x = food_court, y = -0.075), 
               fill = "purple", width = 0.05) +
  scale_x_log10() +
  labs(title = "Food Court Expenditures",
       x = "Money Spent",
       y = "")

p_shop <- train %>%
  ggplot() + 
  geom_density(aes(x = shopping_mall), fill = "purple") + 
  geom_boxplot(aes(x = shopping_mall, y = -0.075), 
               fill = "purple", width = 0.05) +
  scale_x_log10() +
  labs(title = "Shopping Mall Expenditures",
       x = "Money Spent",
       y = "")

p_spa <- train %>%
  ggplot() + 
  geom_density(aes(x = spa), fill = "purple") + 
  geom_boxplot(aes(x = spa, y = -0.075), 
               fill = "purple", width = 0.05) +
  scale_x_log10() +
  labs(title = "Spa Expenditures",
       x = "Money Spent",
       y = "")

p_vr <- train %>%
  ggplot() + 
  geom_density(aes(x = vr_deck), fill = "purple") + 
  geom_boxplot(aes(x = vr_deck, y = -0.075), 
               fill = "purple", width = 0.05) +
  scale_x_log10() +
  labs(title = "VR Deck Expenditures",
       x = "Money Spent",
       y = "")

(p_food + p_shop) / (p_spa + p_vr)
```

The distributions of these variables are all quite similar to one another. The distributions are skewed and 0-inflated. The distributions remain left-skewed even when plotted on a logarithmic scale and the observations at 0 are removed. The mean, median, standard deviation, and interquartile range for each expenditure venue are reported below without the removal of those zero observations.

```{r}
train %>%
  pivot_longer(cols = c("room_service", "food_court", "shopping_mall", "spa", "vr_deck"), 
               names_to = "Venue",
               values_to = "Expenditure") %>%
  select(Venue, Expenditure) %>%
  group_by(Venue) %>%
  summarize(mean_expenditure = mean(Expenditure, na.rm = TRUE),
            median_expenditure = median(Expenditure, na.rm = TRUE),
            sd_expenditure = sd(Expenditure, na.rm = TRUE),
            iqr_expenditure = IQR(Expenditure, na.rm = TRUE)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

The same metrics are reported below after removal of the zero expenditure values. That is, the summary metrics reported below consider only passengers who utilized the corresponding services. These values will align with measures indicated from the log-scale plots above.

```{r}
train %>%
  pivot_longer(cols = c("room_service", "food_court", "shopping_mall", "spa", "vr_deck"), 
               names_to = "Venue",
               values_to = "Expenditure") %>%
  select(Venue, Expenditure) %>%
  filter(Expenditure > 0) %>%
  group_by(Venue) %>%
  summarize(mean_expenditure = mean(Expenditure, na.rm = TRUE),
            median_expenditure = median(Expenditure, na.rm = TRUE),
            sd_expenditure = sd(Expenditure, na.rm = TRUE),
            iqr_expenditure = IQR(Expenditure, na.rm = TRUE)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Below is a visual representation of the distributions for these expenditure variables with the observations at 0 expenditure removed.

```{r}
#| message: false
#| warning: false

train %>%
  pivot_longer(cols = c("room_service", "food_court", "shopping_mall", "spa", "vr_deck"), 
               names_to = "Venue",
               values_to = "Expenditure") %>%
  select(Venue, Expenditure) %>%
  filter(Expenditure > 0) %>%
  ggplot() + 
  geom_density_ridges(aes(x = Expenditure, y = Venue, fill = Venue),
                      scale = 0.5) + 
  geom_boxplot(aes(x = Expenditure, fill = Venue, y = Venue), width = 0.05) + 
  scale_x_log10(labels = scales::dollar_format()) + 
  labs(title = "Expenditure Distributions",
       x = "Money Spent",
       y = "") + 
  theme(legend.position = "None")
```

### Multivariate Analyses

Now that we understand the individual distributions of the variables, its time to look at how these predictors are associated with out response variable (transported). We’ll begin by looking for associations between transported and the categorical variables.

```{r}
p_home <- train %>%
  ggplot() + 
  geom_bar(aes(y = home_planet,
               fill = transported),
           position = "dodge",
           show.legend = FALSE) + 
  labs(title = "Home Planet and Transport",
       x = "Count",
       y = "")

p_cryo <- train %>%
  ggplot() + 
  geom_bar(aes(x = cryo_sleep,
               fill = transported),
           position = "dodge") + 
  labs(title = "Cryo Sleep and Transport",
       x = "",
       y = "Count")

p_destination <- train %>%
  ggplot() + 
  geom_bar(aes(y = destination,
               fill = transported),
           position = "dodge",
           show.legend = FALSE) + 
  labs(title = "Destination and Transport",
       x = "Count",
       y = "")

p_vip <- train %>%
  ggplot() + 
  geom_bar(aes(x = vip,
               fill = transported),
           position = "fill",
           show.legend = FALSE) + 
  labs(title = "VIP Status and Transport",
       x = "",
       y = "Proportion")

(p_home + p_cryo) / (p_destination + p_vip)
```

From the four plots above, we have the following takeaways. First, the plot on the left shows the passengers from Europa were much more likely to be transported than passengers from Mars or Earth. Passengers from Earth had a less than 50% transport rate while passengers from Mars had a slightly larger than 50% transport rate. Passengers in Cryo Sleep had an extremely elevated likelihood of transport than those who did not take advantage of Cryo Sleep. There were slight differences in transport rates by destination and by VIP status, but the choice to undergo Cryo Sleep seems to have been the largest influence over whether passengers were transported or not.

Now we’ll consider how the numerical features may be associated with the `transported` status of passengers.

```{r}
#| message: false
#| warning: false

train %>%
  pivot_longer(cols = c("room_service", "food_court", "shopping_mall", "spa", "vr_deck"), 
               names_to = "Venue",
               values_to = "Expenditure") %>%
  mutate(transported = ifelse(transported == "yes", "transported", "not")) %>%
  ggplot() + 
  geom_boxplot(aes(x = Expenditure,
                   y = transported,
                   fill = Venue),
               show.legend = FALSE) +
  scale_x_log10() +
  facet_wrap(~Venue) + 
  labs(title = "",
       x = "Expenditure",
       y = "")
```

In the group of plots appearing above, we see that higher food court and shopping mall expenditures were associate with those passengers who were transported than those who were not. Those individuals not being transported had higher room service, spa, and VR deck expenditures on average than those who were not transported.

As a result of this exploratory analysis, we’ve identified several important insights as we proceed to the model construction phase of this analysis. Firstly, about half of passengers were transported to an alternate dimension while the other half were transported safely. All of the numerical features are very heavily right-skewed aside from age. The variable most strongly associated with whether or not a passenger was transported may be the choice to Cryo Sleep during the flight. Other variables showed associations as well, but were less pronounced.

## Model Construction and Assessment

:::{.callout-important}
## Statistical Learning versus Machine Learning

There are two competing objectives that we can have in model construction. 

+ **Statistical Learning:** We build models with the intent of discovering and interpreting associations between our available predictors and the response.
  
  + Fits models and then uses $p$-values to identify significant predictors, confidence intervals for coefficients, etc.

+ **Machine Learning:** We build models with the intent of making predictions as accurately as possible. 

  + Uses methods like *cross-validation* for hyperparameter tuning and performance estimation

You do not necessarily need to choose just one approach or the other. Perhaps the problems/challenges you’ve set out to solve would benefit from both descriptive and predictive models. In this case, just make clear to the reader when you are switching between objectives.
:::

### Statistical Learning

#### Logistic Regression

e^(intecept + coef1x1 + coef2x2...) / 1 + e^(intecept + coef1x1 + coef2x2...) 

1. can interpret the coefs...
higher coef means higher likelinehood of class 1 (rather than class 0 ) - > (makes the prediction higher;closer to 1)


2. for categorical variables, e^coef gives the odds of belonging to class 1 (using dummy variables)

3. using calculus, we can take partial derivatives (or use marginaleffects) for numeric variables 

```{r}
logReg_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

logReg_rec <- recipe(transported ~ ., data = train) %>% 
  step_rm(passenger_id) %>% 
  step_rm(name) %>% 
  step_mutate(deck = as.factor( substr(cabin, 1, 1) ) ) %>%  #change add column based on cabin to get deck
  step_rm(cabin) %>% 
  step_impute_median(all_numeric_predictors()) %>%  #median is more resistant to outliers than mean....better measurement of "center"
  step_impute_mode(all_nominal_predictors()) %>%  #most common category
  step_dummy(all_nominal_predictors())

logReg_wf <- workflow() %>% 
  add_model(logReg_spec) %>% 
  add_recipe(logReg_rec)

logReg_fit <- logReg_wf %>% 
  fit(train)


logReg_fit %>% 
  extract_fit_engine() %>% 
  tidy() %>% 
  mutate(                                 #the ratio says x times more likely accounting for everything but the thing ur lookin at
    odds_ratio = exp(estimate),                 #for categorical, it is compared to the baked in dummy part....
    odds_lower = exp(estimate - 2*std.error),        
    odds_upper = exp(estimate + 2*std.error)
    )  #most meaningful for categorical predictors
#for example, home_planet_europa has odds_ratio of 5.3, which means that it is 5.3 times more likely that a europa passenger is transported than an earth passenger (because earth was the dummy bit that was baked in....the default basically)

```

```{r}


new_data <- crossing(
  passenger_id = NA,
  home_planet = "Europa",
  cryo_sleep = "no",
  cabin = "A",   #will bozo me prolly
  destination = "TRAPPIST-1e",
  age = mean(train$age, na.rm = TRUE),
  vip = "no",
  room_service = mean(train$room_service, na.rm = TRUE),
  food_court = mean(train$food_court, na.rm = TRUE),
  shopping_mall = mean(train$shopping_mall, na.rm = TRUE),
  spa = mean(train$spa, na.rm = TRUE),
  vr_deck = seq(min(train$vr_deck, na.rm = TRUE),
            max(train$vr_deck, na.rm = TRUE),
            by = 1),
  name = NA
)





new_data_baked <- logReg_rec %>%
  prep() %>%
  bake(new_data)

mfx <- slopes(logReg_fit %>% extract_fit_parsnip(),
              newdata = new_data_baked,
              variables = "vr_deck",
              type = "prob") %>%
  tibble()

mfx %>%
  select(term, vr_deck, estimate, conf.low, conf.high, std.error) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))

mfx %>%
  arrange(vr_deck)

mfx %>%
  filter(group == "yes") %>%
  select(vr_deck, estimate, conf.low, conf.high) %>%
  ggplot() +
  geom_line(aes(x = vr_deck, y = estimate), color = "purple", lty = "dashed", lwd = 1.5) +
  geom_ribbon(aes(x = vr_deck, ymin = conf.low, ymax = conf.high),
              fill = "grey", alpha = 0.5) +
  labs(x = "Age",
       y = "Marginal Effect",
       title = "Marginal Effects of Unit Increase in Weight")








```

### Confusion Matrix 

inspect these to look for ways to improve

```{r}

logReg_fit %>% 
  augment(train)      #per passenger liklihood based on model


logReg_fit %>% 
  augment(train) %>%    #same results, grouped by yes/no liklihood based on model
  conf_mat(transported, .pred_class)


```
```{r}

#separating out false-negative vs false-positives and corrects

logReg_fit %>% 
  augment(train) %>% 
  mutate(
    correct_flag = ifelse(transported == .pred_class, "correct",
                          ifelse(transported == "yes", 
                                 "false-negative", "false-positive") )   #truly an if....else
  ) %>% 
  filter(correct_flag == "false-negative") 



logReg_fit %>% 
  augment(train) %>% 
  mutate(
    correct_flag = ifelse(transported == .pred_class, "correct",
                          ifelse(transported == "yes", 
                                 "false-negative", "false-positive") )   #truly an if....else
  ) %>% 
  filter(correct_flag == "false-positive") 



logReg_fit %>% 
  augment(train) %>% 
  mutate(
    correct_flag = ifelse(transported == .pred_class, "correct",
                          ifelse(transported == "yes", 
                                 "false-negative", "false-positive") )   #truly an if....else
  ) %>% 
  group_by(correct_flag) %>% 
  summarize(
    median_food_spend = median(food_court, na.rm = TRUE)
  )

#OR USE CASES INSTEAD OF NESTED IFELSE:


logReg_fit %>% 
  augment(train) %>% 
  mutate(
    correct_flag = case_when(
      transported == .pred_class ~ "correct prediction",             #case 1, they match, make it yes
      transported == "yes" ~ "false-negative",                        #case 2, not case 1 ppl, got transported but we said they wouldnt
      TRUE ~ "false-positve" #everyone else.....everyone that isnt false negative or correct
    )) %>%
  group_by(correct_flag) %>%
  summarize(
    median_food_spend = median(food_court, na.rm = TRUE)
  )





```


perf metrics: (in video tooo)

different metrics prioritize/optimize different outcomes (false negative/false positive). And by using a specific one that fits your circumstance while you model, you get the model thats best for that circumstance.

accuracy -  all equal....differentiates between true prediction and false prediction only. 

recall - dont want false negatives (using this for titanic is like: bruh we really dont wanna sell a ticket to someone if theyve got any sort of chance of being teleported)   (ability to flag class were interested in...likelihood we correctly predict true)

precision - likeliehood we correctly predict false. Ability to accurately predict adbsense of interested class. 


### Machine Learning

```{r}

 test %>% 
  mutate(deck = as.factor( substr(cabin, 1, 1) ) ) 

 train %>% 
  mutate(deck = as.factor( substr(cabin, 1, 1) ) ) 


set.seed(123) #write set seed before every random thing we do 
train_folds <- vfold_cv(train, v = 10, strata = transported)




```



#### Logistic Regression

```{r}


#creating a set of accuracy metrics we are interested in 
my_metrics <- metric_set(accuracy, precision, recall)


#USING CROSS VALIDATION.....trying to reduce overfitness, lets you mix/max, and tune
logReg_cv_results <- logReg_wf %>% 
  fit_resamples(
    resamples = train_folds,
    metrics = my_metrics
  )


logReg_cv_results %>% 
  collect_metrics() #put summarize = FALSE   in the parens if you want all the metrics


```

regression cuz it gives a number 0-1.....percent chacne of belonging to class of interest. 
Works best when there are only two categories : especially true/false, yes/no 

but predicting something with more than two poessible values, would need multiple logistic regression models....could predict category that has highest prediction for it 



#### HyperParameter Tuning 


lasso/ridge can be used with any model type that has beta coefficients basically. 
they are optimizing budget to optimize model performance on new data and minimize overfitting. 
https://agmath.github.io/ClassificationCourse/Day8b_LogisticRegression_Intro.html#hyperparameters-and-other-extras

need to scale numeric predictors so that nothing is artificially "expensive" or "cheap" for Lasso/ridge to choose with its budget



```{r}
logReg_tune_spec <- logistic_reg(penalty = tune(), mixture = tune() ) %>% 
  set_engine("glmnet") %>%  #used because it has the penalty and mixture hyperparams
  set_mode("classification")


#copied from before mostly
#step_range to scale things between 0 and 1
logReg_tune_rec <- recipe(transported ~ ., data = train) %>% 
  step_rm(passenger_id) %>% 
  step_rm(name) %>% 
  step_mutate(deck = as.factor( substr(cabin, 1, 1) ) ) %>%  #change add column based on cabin to get deck
  step_rm(cabin) %>% 
  step_impute_median(all_numeric_predictors()) %>%  #median is more resistant to outliers than mean....better measurement of "center"
  step_impute_mode(all_nominal_predictors()) %>%  #most common category
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors()) #converting to standard deviations above and below mean....alternative is step_range


#step_range and step_normalize are alternatives....one will be better....tune for both for best model
#range is converting 0-1
#normalize is converting to standard deviation scaling....how many standard deviations value is away from mean


logReg_tune_wf <- workflow() %>% 
  add_model(logReg_tune_spec) %>% 
  add_recipe(logReg_tune_rec)


#if there are rows with missing outcome variables, just get rid of them...they cannot help
#there are not here, but remember that











```



Tunint our penalty and mixture hyperparamaters 

ridge regression - mixture 0 - priortitize small coef

lasso - mixture 1 - coefs can be exactly 0 
To say that, lasso will be able to get rid of crap predictors - we dont have to worry about it, so give it everything
and if that matters, then tuning the mixture will do it for you 



```{r}


#great for specifying where you want to look...how granular you want to look
param_grid <- crossing( #think cross multiply....every possible pair
  penalty = c(0.1, 1, 10, 100), #typical values are powers of ten
  mixture = seq(0,1, by = 0.1), #o-1 increment by 0.1
)


param_grid #44 combos here


#OR....fill over x random, equally spaced points

Logreg_tune_results <- logReg_tune_wf %>% 
  tune_grid(
    resamples = train_folds,
    grid = 12,
    metrics = metric_set(accuracy, precision, recall) #the metrics we care about
    )
#can put the param_grid here for grid....would do 44 combos.....if you set to just a number x, its x  space-filling points in the hyperparameter space 



Logreg_tune_results %>% 
  show_best(n = 10, metric = "recall")
  



```

convex loss surface: we want a big pit where the best results are. We want every other tune combo in the hyperparam space to lead to the big pit....we dont want to get stuck in a false pit...where it looks like theres no better way out, but there actually is 

But so, now for improvements, we look at good combos and zoom in? 

```{r}

#didnt finish running
logReg_seq_tune_results <- logReg_tune_wf %>% 
  tune_bayes(
    resamples = train_folds, 
    iter = 20, #walking around the space 
    metrics = metric_set(recall), #really prioritize one metric here....walk in the direction of the metric we care about 
    initial = Logreg_tune_results #our previous results...start from there...if its a number x, itll do the x space filling points
  )
  
#theres a step size hyperparamater....determiens how long of a step it takes...can over step
#can take large steps at first, then take smaller steps..take steps of decaying size 

#stops running if it doesnt improve after 10 iterations

logReg_seq_tune_results %>% 
  show_best(n=10, metric = "recall")


```




## Model Interpretation and Inference

## Conclusion

## References


